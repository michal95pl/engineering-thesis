\setcounter{chapter}{9}
\addtocontents{toc}{\protect\newpage}
\chapter[Graficzny interfejs użytkownika {[\textit{Marcin Ziółkowski}]}]{Graficzny interfejs użytkownika}

Interfejs graficzny systemu został zaprojektowany w celu zapewnienia intuicyjnej obsługi procesu kalibracji oraz wizualizacji stanu gry w czasie rzeczywistym. Aplikacja została zrealizowana w języku Python z wykorzystaniem biblioteki \texttt{tkinter}.

\section{Architektura i przepływ aplikacji}
Główny punkt wejścia aplikacji, zdefiniowany w pliku \texttt{main.py}, zarządza cyklem życia okien i logiką przełączania stron. Wykorzystano mechanizm \textit{listenerów}, który pozwala na niszczenie poprzednich widoków i inicjalizację nowych po spełnieniu określonych warunków (np. wybraniu kamery).



Proces uruchomienia systemu przebiega w trzech krokach:
\begin{enumerate}
    \item \textbf{Wybór urządzenia:} Wykrycie i selekcja aktywnego źródła obrazu.
    \item \textbf{Kalibracja kolorów:} Wskazanie markerów perspektywy na obrazie na żywo.
    \item \textbf{Panel gry:} Monitorowanie szachownicy i wyświetlanie wirtualnej tablicy.
\end{enumerate}

\section{Inicjalizacja i kalibracja}
\subsection{Wybór kamery (CameraSelectPage)}
Klasa \texttt{CameraSelectPage} odpowiada za skanowanie portów systemowych w poszukiwaniu dostępnych urządzeń wideo. Metoda statyczna \texttt{get\_available\_cameras} próbuje otworzyć strumień \texttt{cv2.VideoCapture} dla kolejnych indeksów, co eliminuje błędy wyboru nieistniejących urządzeń.

\subsection{Kalibracja markerów (ColorCalibrationPage)}
Po wyborze kamery, system przechodzi do widoku \texttt{ColorCalibrationPage}. Jest to kluczowy etap dla modułu \texttt{BoardTransformation}. Użytkownik, klikając na podgląd wideo, wybiera próbki kolorów dla zielonych i czerwonych znaczników umieszczonych na rogach szachownicy. Wybrane wartości RGB są wizualizowane, co daje natychmiastową informację zwrotną o poprawności wyboru.

\section{Integracja obrazu wideo (VideoFrame)}
Najbardziej złożonym elementem GUI jest klasa \texttt{VideoFrame}, która dziedziczy po \texttt{threading.Thread}. Dzięki pracy w osobnym wątku, obliczenia związane z przetwarzaniem obrazu i sieci neuronowej nie blokują głównej pętli zdarzeń interfejsu.

\begin{lstlisting}[style=codeListingStyle, caption={Integracja OpenCV z Tkinter w osobnym wątku}]
def run(self):
    cap = cv2.VideoCapture(self.camera_index)
    while self.update_video:
        ret, frame = cap.read()
        if ret:
            # Przetwarzanie obrazu
            if self.board_transformation:
                frame = self.board_transformation.apply(frame)
            
            # Konwersja BGR do RGB dla Tkinter
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            self.show_frame(frame_rgb)
\end{lstlisting}

\texttt{VideoFrame} pełni rolę kontrolera danych – to tutaj inicjalizowany jest model \texttt{ChessCNN} oraz obiekt \texttt{JsonUpdater}, który zarządza historią ruchów.

\section{Wizualizacja stanu gry (ChessGUI)}
Panel gry (\texttt{GamePage}) dzieli ekran na dwie sekcje. Po lewej stronie wyświetlany jest przetworzony strumień wideo (szachownica po transformacji perspektywicznej), a po prawej wirtualna tablica generowana przez klasę \texttt{ChessGUI}.

\texttt{ChessGUI} renderuje stan gry na obiekcie \texttt{tk.Canvas}, mapując symbole bierek (pobierane z \texttt{VideoFrame.get\_board\_state}) na odpowiednie ikony graficzne.

\begin{lstlisting}[style=codeListingStyle, caption={Mapowanie symboli na zasoby graficzne}]
def _load_images(self):
    mapping = {
        'r': 'black_rook.png', 'n': 'black_knight.png', 
        'R': 'white_rook.png', 'N': 'white_knight.png',
        # ... reszta bierek
    }
    for k, v in mapping.items():
        img = Image.open(f"./assets/chessgui/{v}").resize((45, 45))
        self.images[k] = ImageTk.PhotoImage(img)
\end{lstlisting}



Dzięki zastosowaniu metody \texttt{after()} w bibliotece \texttt{tkinter}, widok \texttt{ChessGUI} jest odświeżany cyklicznie, co pozwala na płynną synchronizację między fizycznym ruchem wykonanym na szachownicy a jego cyfrową reprezentacją.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{chapters/chess_identification/images/MainFrame.png}
    \caption{Przykład gotowego widoku.}
\end{figure}

\section{Logika sterowania i etapy inicjalizacji}
Aplikacja działa w oparciu o sekwencyjny model inicjalizacji, który zapewnia, że moduły wizyjne i komunikacyjne otrzymają poprawne parametry wejściowe przed rozpoczęciem właściwej rozgrywki. Proces ten można podzielić na następujące fazy:

\subsection{Uruchomienie i wybór urządzenia (Startup)}
Po uruchomieniu modułu \texttt{main.py} następuje resetowanie logów oraz próba nawiązania połączenia z serwerem silnika szachowego za pomocą klasy \texttt{Communication}. Jeśli połączenie zostanie nawiązane, wyświetlane jest okno \texttt{CameraSelectPage}. Program skanuje systemowe indeksy urządzeń (0--3), a użytkownik z listy rozwijanej wybiera kamerę, która ma służyć do monitorowania szachownicy.

\subsection{Kalibracja markerów i perspektywy}
Po wyborze kamery wywoływany jest \textit{listener}, który niszczy interfejs wyboru i inicjalizuje \texttt{ColorCalibrationPage}. Na tym etapie:
\begin{enumerate}
    \item Wyświetlany jest podgląd wideo na żywo.
    \item Użytkownik wskazuje kursorem myszy zielone i czerwone znaczniki na rogach szachownicy.
    \item System pobiera wartości RGB klikniętych pikseli, które posłużą klasie \texttt{BoardTransformation} do progowania i ekstrakcji narożników szachownicy.
    \item Po zatwierdzeniu wyboru przyciskiem „Ok”, parametry koloru są przekazywane dalej do głównego modułu gry.
\end{enumerate}



\subsection{Pętla gry i komunikacja z silnikiem}
Właściwa logika gry odbywa się wewnątrz klasy \texttt{VideoFrame}, pracującej jako osobny wątek. Przepływ danych w jednej iteracji pętli wygląda następująco:
\begin{itemize}
    \item \textbf{Przetwarzanie obrazu:} Pobranie klatki $\rightarrow$ Transformacja perspektywiczna $\rightarrow$ Identyfikacja bierek za pomocą \texttt{ChessCNN}.
    \item \textbf{Zapis stanu:} Wykryta tablica (lista 8x8) jest przekazywana do \texttt{JsonUpdater}, który konwertuje ją na notację FEN i zapisuje w pliku \texttt{data.json}.
    \item \textbf{Zarządzanie turą:} System sprawdza, czyja jest tura (\texttt{check\_turn}). Jeśli wykryto ruch białych (gracza), system wysyła aktualny stan FEN do serwera.
    \item \textbf{Interakcja z serwerem:} Serwer analizuje pozycję i odsyła najlepszy ruch dla czarnych. System oczekuje na ten ruch (z timeoutem 15 sekund).
    \item \textbf{Weryfikacja ruchu:} Po otrzymaniu odpowiedzi od serwera, interfejs wirtualny (\texttt{ChessGUI}) aktualizuje pozycję. System przechodzi w stan oczekiwania na fizyczne wykonanie ruchu w imieniu przeciwnika (komputera), stale porównując obraz z kamery z oczekiwanym stanem logicznym.
\end{itemize}